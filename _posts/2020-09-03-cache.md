---
layout:     post
title:      "缓存学习笔记"
autor:      "dusmart"
tags:
    - notes
---

<!--more-->

# 缓存的更新模式

> Attention 这几种模式不考虑实际工程中缓存层和持久层的事务问题，假设操作均不会失败

- Cache Aside 更新模式
- Read/Write Through 更新模式
- Write Behind Caching 更新模式

### Cache Aside 模式

- 读取数据：读缓存，缓存失效则读持久层，成功后写回缓存；读缓存，缓存命中则直接返回
- 更新/删除：先更新持久层，再失效缓存



**避坑**：

1. 缓存更新步骤更改为：先更新持久层，再**更新**缓存

​      坑点在于双写并发操作，如果请求一先更新了持久层，请求二后更新了持久层，请求二更新完缓存，请求一才更新完缓存；缓存层和持久层不一致

2. 缓存更新步骤更改为：先失效缓存，再更新持久层

​      坑点在于读写并发操作，如果写请求先失效了缓存，读请求读不到缓存，读请求从持久层读取后写回缓存，写请求继续更新持久层；缓存层和持久层不一致

**极端情况下的不一致：**

坑点在于缓存因冷启动或过期无数据的情况下读写并发操作，读请求读不到缓存，读请求从持久层读取到老数据，写请求更新持久层，写请求失效缓存，读请求将老数据写入缓存；缓存和持久层不一致



![img](/assets/img/2020-09-03/535a5385-cc30-4ab6-bc7f-20ead69fd8c9.png)

![img](/assets/img/2020-09-03/4b681102-c15c-45b3-ba71-38c7bb6e6118.png)

[图1. CacheAside 《缓存更新的套路》](https://coolshell.cn/articles/17416.html)



### Read Through 模式 && Write Through 模式

- 读取数据：直接读缓存，缓存自己负责失效时从持久层获取并缓存数据
- 写入数据：命中缓存则更新缓存，缓存自己负责同步写入到持久层；未命中缓存则直接写入持久层

好处：操作简单，应用直接和缓存打交道

坏处：需要缓存自己提供额外支持，写入效率不高

![img](/assets/img/2020-09-03/88dd69c3-584d-4c22-8095-161eee252b95.png)

[图2. Read/Write Through 《缓存Wiki》](https://en.wikipedia.org/wiki/Cache_(computing))

### Write Behind 模式 (Write Alloc)

- 读取数据：命中缓存则直接读取，未命中缓存则需要缓存从持久层读取数据
- 写入数据：只更新缓存，不更新持久层，而缓存会异步地批量更新持久层
- **注意！**无论读写如果需要挤出已更新到缓存但未持久化的数据，需要提前将这些数据写入持久层



好处：I/O速度飞快，多份对持久层的写入操作可以合并进行

坏处：数据不是强一致性的，而且可能会丢失

![img](/assets/img/2020-09-03/83b7e442-b39d-4bcf-969e-ba0e0a79cb81.png)

[图3. Write Behind 《缓存Wiki》](https://en.wikipedia.org/wiki/Cache_(computing))

# 缓存常见问题



## 缓存穿透

> 数据在持久层是没有的，在缓存中自然也没有（例如 xxx_id = 0），所以，在缓存中查不到就会去持久层查询，这样的请求一多，那么我们的持久层的压力会变大。

解决办法：

1. 对于空数据也进行缓存
2. 利用数据特征以及[布隆过滤器](https://zh.wikipedia.org/wiki/布隆过滤器)等方法过滤掉不可能存在的数据



布隆过滤器：利用多个不同的哈希函数快速判断一个数据是否存在于持久层，如果布隆过滤器给出的结论是不存在那必然不存在，否则可能是存在的



## 缓存击穿

> 热点数据过期，大量请求直接打到持久层

解决办法：

1. [SingleFlight](https://segmentfault.com/a/1190000018464029) 或者分布式锁，保证对同一资源的访问同一时刻只有一个（单机或全体）
2. 定时任务，及时刷新缓存和过期时间



## 缓存雪崩

> 缓存又双叒叕临时抖动了，或者大量缓存由于超时时间相同在同时失效

解决办法：

1. 多级缓存 （更容易出现不一致）
2. 分布式，多搞一些缓存实例
3. 过期时间随机化
4. [SingleFlight](https://segmentfault.com/a/1190000018464029) 或者分布式锁缓解压力，保证对同一资源的访问同一时刻只有一个（单机或全体）



## 如何避免数据不一致

1. 设置过期时间，保证数据的最终一致性
2. 考虑到数据库读写库分离的延迟问题，Cache Aside 模式需要做出延迟失效的策略调整：
   1. 先更新持久层，再失效缓存，再起一个协程等X毫秒失效缓存（X 毫秒略大于读写库的延迟时间），为了缓存失效避免后的读请求将老旧的数据重新载入缓存导致不一致，同时这个策略也可以解决上述Cache Aside 模式在极端情况下不一致的情况
   2. 如果采用消息队列异步清缓存，可以考虑延迟消息
   3. 考虑直接读主库
3. Cache Aside 模式更新缓存的步骤中操作持久层成功，第二步失效缓存时失败：
   1. 改用可靠的 binLog 消息队列
4. 考虑下其他不带缓存的设计，缓存是通过牺牲强一致性来提高性能的。所以使用缓存提升性能，就是会有数据不一致的风险。这需要我们在设计时结合业务仔细思考是否适合用缓存。





# SingleFlight

> 初次接触 SingleFlight 是阅读 tcc_client 的代码的时候，使用非常简单，源码更简单

Tcc 为了避免多个请求对同一个 Key 的读取的冗余访问，采用了这个库去兜底，当真正决定了要去拉取服务端数据的时候，使用 service+confspace 作为 key，拉取整个 service 下的所有配置。

```
func (c *ClientV2) getAndCache(ctx context.Context, cacheData *Data) (*Data, error) {
       datai, err, _ := c.sf.Do(c.serviceName+"@"+c.confspace, func() (interface{}, error) {
              data, err := c.getFromServer(ctx, cacheData)
              if err == nil || err == ConfigNotFoundError {
                     c.cache.Set(data, err)
                     return data, err
              }
              if cacheData != nil {
                     c.cache.Set(cacheData, nil)
                     return cacheData, nil
              }
              // if the first three times get data failed, do not cache the error
              if atomic.LoadUint64(&c.getCount) > MaxDontCacheCount || atomic.LoadUint64(&c.getSuccCount) > 0 {
                     c.cache.Set(nil, err)
              }
              return nil, err
       })

       if err != nil {
              return nil, err
       }
       return datai.(*Data), nil
}
```

本质上是使用一个带锁的 Map，保证同一时刻对同一个 key 的访问只存在一个操作。

```
func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) {
       g.mu.Lock()
       // 保证 map 的初始化
       if g.m == nil {
              g.m = make(map[string]*call)
       }
       // 如果对于该 key 已经有在执行的请求 c 了，就等他结束，直接拿他的结果
       if c, ok := g.m[key]; ok {
              c.dups++
              g.mu.Unlock()
              c.wg.Wait()
              return c.val, c.err, true
       }
       // 否则开一个真正的请求 c，等待执行完成后返回该结果
       c := new(call)
       c.wg.Add(1)
       g.m[key] = c
       g.mu.Unlock()

       g.doCall(c, key, fn)
       return c.val, c.err, c.dups > 0
}
```



# 参考文档

https://juejin.im/post/6844903665845665805

https://www.jianshu.com/p/439b57dd224e
